diff --git a/cmake/external/grpc.cmake b/cmake/external/grpc.cmake
index 536e95c1dc..8c5a434048 100644
--- a/cmake/external/grpc.cmake
+++ b/cmake/external/grpc.cmake
@@ -13,6 +13,39 @@
 # limitations under the License.
 #

+IF(NOT WITH_DISTRIBUTE)
+    return()
+ENDIF()
+
+IF(WITH_SYSTEM_GRPC)
+  FIND_PACKAGE(PkgConfig REQUIRED)
+  PKG_CHECK_MODULES(GPR REQUIRED gpr)
+  PKG_CHECK_MODULES(GRPC REQUIRED grpc)
+  PKG_CHECK_MODULES(GRPC_UNSECURE REQUIRED grpc_unsecure)
+  PKG_CHECK_MODULES(GRPC++ REQUIRED grpc++)
+  PKG_CHECK_MODULES(GRPC++_UNSECURE REQUIRED grpc++_unsecure)
+
+  ADD_LIBRARY(extern_grpc INTERFACE IMPORTED GLOBAL)
+  ADD_LIBRARY(gpr INTERFACE IMPORTED GLOBAL)
+  ADD_LIBRARY(grpc INTERFACE IMPORTED GLOBAL)
+  ADD_LIBRARY(grpc_unsecure INTERFACE IMPORTED GLOBAL)
+  ADD_LIBRARY(grpc++ INTERFACE IMPORTED GLOBAL)
+  ADD_LIBRARY(grpc++_unsecure INTERFACE IMPORTED GLOBAL)
+
+  SET_PROPERTY(TARGET extern_grpc PROPERTY IMPORTED_LIBNAME grpc)
+  SET_PROPERTY(TARGET gpr PROPERTY IMPORTED_LIBNAME gpr)
+  SET_PROPERTY(TARGET grpc PROPERTY IMPORTED_LIBNAME grpc)
+  SET_PROPERTY(TARGET grpc_unsecure PROPERTY IMPORTED_LIBNAME grpc_unsecure)
+  SET_PROPERTY(TARGET grpc++ PROPERTY IMPORTED_LIBNAME grpc++)
+  SET_PROPERTY(TARGET grpc++_unsecure PROPERTY IMPORTED_LIBNAME grpc++_unsecure)
+
+  FIND_PROGRAM(GRPC_CPP_PLUGIN NAMES grpc_cpp_plugin)
+  SET(GRPC_INCLUDE_DIR ${GRPC_INCLUDE_DIRS} CACHE PATH "grpc include directory." FORCE)
+
+  ADD_DEPENDENCIES(extern_grpc zlib protobuf)
+  RETURN()
+ENDIF()
+
 include (ExternalProject)

 SET(GRPC_SOURCES_DIR ${THIRD_PARTY_PATH}/grpc)
diff --git a/paddle/fluid/operators/distributed/grpc/grpc_client.h b/paddle/fluid/operators/distributed/grpc/grpc_client.h
index 22ca74a67e..fbf2a3c407 100644
--- a/paddle/fluid/operators/distributed/grpc/grpc_client.h
+++ b/paddle/fluid/operators/distributed/grpc/grpc_client.h
@@ -46,9 +46,6 @@ limitations under the License. */
 #include "paddle/fluid/operators/distributed/sendrecvop_utils.h"
 #include "paddle/fluid/platform/macros.h"  // for DISABLE_COPY_AND_ASSIGN

-namespace grpc {
-class Channel;
-}  // namespace grpc
 namespace paddle {
 namespace framework {
 class Scope;
diff --git a/paddle/fluid/operators/distributed/grpc/grpc_server.cc b/paddle/fluid/operators/distributed/grpc/grpc_server.cc
index 47e114ff4b..16eedc827e 100644
--- a/paddle/fluid/operators/distributed/grpc/grpc_server.cc
+++ b/paddle/fluid/operators/distributed/grpc/grpc_server.cc
@@ -20,9 +20,6 @@ limitations under the License. */
 #include "paddle/fluid/operators/distributed/grpc/grpc_serde.h"
 #include "paddle/fluid/operators/distributed/grpc/grpc_server.h"

-namespace grpc {
-class ChannelArguments;
-}  // namespace grpc
 namespace paddle {
 namespace framework {
 class Variable;
diff --git a/paddle/fluid/operators/distributed/grpc/grpc_server.h b/paddle/fluid/operators/distributed/grpc/grpc_server.h
index 3d68b7e8ce..ee6950205b 100644
--- a/paddle/fluid/operators/distributed/grpc/grpc_server.h
+++ b/paddle/fluid/operators/distributed/grpc/grpc_server.h
@@ -37,10 +37,6 @@ limitations under the License. */
 #include "paddle/fluid/operators/distributed/sendrecvop_utils.h"
 #include "paddle/fluid/platform/profiler.h"

-namespace grpc {
-class ServerCompletionQueue;
-}  // namespace grpc
-
 namespace paddle {
 namespace operators {
 namespace distributed {
diff --git a/paddle/fluid/operators/distributed/grpc/grpc_service.h b/paddle/fluid/operators/distributed/grpc/grpc_service.h
index 95b6810ec6..f9180522bd 100644
--- a/paddle/fluid/operators/distributed/grpc/grpc_service.h
+++ b/paddle/fluid/operators/distributed/grpc/grpc_service.h
@@ -32,11 +32,6 @@
 //       requests without too much copying of the tensor data.

 namespace grpc {
-class CompletionQueue;
-class Channel;
-class RpcService;
-class ServerCompletionQueue;
-class ServerContext;

 // Support parsing/unparsing of tensorflow::VariableResponse.
 // Wire-format is identical to RecvVariableResponse.
diff --git a/cmake/external/warpctc.cmake b/cmake/external/warpctc.cmake
index 2a9600dec5..b9cfceb190 100644
--- a/cmake/external/warpctc.cmake
+++ b/cmake/external/warpctc.cmake
@@ -56,6 +56,7 @@ ExternalProject_Add(
                     -DCMAKE_CXX_FLAGS_DEBUG=${CMAKE_CXX_FLAGS_DEBUG}
                     -DCMAKE_INSTALL_PREFIX=${WARPCTC_INSTALL_DIR}
                     -DWITH_GPU=${WITH_GPU}
+                    -DCUDA_VERSION=8.0
                     -DWITH_OMP=${USE_OMP}
                     -DWITH_TORCH=OFF
                     -DCMAKE_DISABLE_FIND_PACKAGE_Torch=ON
diff --git a/cmake/flags.cmake b/cmake/flags.cmake
index 884e5d45a6..b80c13bd58 100644
--- a/cmake/flags.cmake
+++ b/cmake/flags.cmake
@@ -143,13 +143,10 @@ set(COMMON_FLAGS
     -Werror
     -Wall
     -Wextra
-    -Wnon-virtual-dtor
-    -Wdelete-non-virtual-dtor
     -Wno-unused-parameter
     -Wno-unused-function
     -Wno-error=literal-suffix
     -Wno-error=unused-local-typedefs
-    -Wno-error=parentheses-equality # Warnings in pybind11
     -Wno-error=ignored-attributes  # Warnings in Eigen, gcc 6.3
     -Wno-error=terminate  # Warning in PADDLE_ENFORCE
     -Wno-error=int-in-bool-context # Warning in Eigen gcc 7.2
@@ -178,8 +175,6 @@ endif(NOT APPLE)
 set(GPU_COMMON_FLAGS
     -fPIC
     -fno-omit-frame-pointer
-    -Wnon-virtual-dtor
-    -Wdelete-non-virtual-dtor
     -Wno-unused-parameter
     -Wno-unused-function
     -Wno-error=literal-suffix
diff --git a/cmake/external/protobuf.cmake b/cmake/external/protobuf.cmake
index 04f22d7fc8..e969a72037 100644
--- a/cmake/external/protobuf.cmake
+++ b/cmake/external/protobuf.cmake
@@ -132,7 +132,7 @@ macro(SET_PROTOBUF_VERSION)
     STRING(REGEX MATCH "[0-9]+.[0-9]+" PROTOBUF_VERSION "${PROTOBUF_VERSION}")
 endmacro()

-set(PROTOBUF_ROOT "" CACHE PATH "Folder contains protobuf")
+set(PROTOBUF_ROOT "/usr" CACHE PATH "Folder contains protobuf")
 IF (WIN32)
     SET(PROTOBUF_ROOT ${THIRD_PARTY_PATH}/install/protobuf)
 ENDIF(WIN32)
@@ -234,7 +234,7 @@ FUNCTION(build_protobuf TARGET_NAME BUILD_FOR_HOST)
     )
 ENDFUNCTION()

-SET(PROTOBUF_VERSION 3.1.0)
+SET(PROTOBUF_VERSION 3.12.0)

 IF(NOT PROTOBUF_FOUND)
     build_protobuf(extern_protobuf FALSE)
diff --git a/paddle/fluid/framework/ir/coalesce_grad_tensor_pass.h b/paddle/fluid/framework/ir/coalesce_grad_tensor_pass.h
index 38dc4c99fc..a7022e81ae 100644
--- a/paddle/fluid/framework/ir/coalesce_grad_tensor_pass.h
+++ b/paddle/fluid/framework/ir/coalesce_grad_tensor_pass.h
@@ -13,6 +13,7 @@
 // limitations under the License.
 #pragma once
 #include <algorithm>
+#include <cstdint>

 namespace paddle {
 namespace framework {
diff --git a/CMakeLists.txt b/CMakeLists.txt
index d0cff762e2..c05b9dbabd 100755
--- a/CMakeLists.txt
+++ b/CMakeLists.txt
@@ -136,6 +136,7 @@ option(WITH_BOX_PS      "Compile with box_ps support"                   OFF)
 option(WITH_XBYAK       "Compile with xbyak support"                    ON)
 option(WITH_CONTRIB     "Compile the third-party contributation"        OFF)
 option(WITH_GRPC     "Use grpc as the default rpc framework"            ${WITH_DISTRIBUTE})
+option(WITH_SYSTEM_GRPC  "Use system grpc instead of third party"       OFF)
 option(WITH_INFERENCE_API_TEST   "Test fluid inference C++ high-level api interface"  OFF)
 option(PY_VERSION       "Compile PaddlePaddle with python3 support"     ${PY_VERSION})
 option(WITH_DGC   "Use DGC(Deep Gradient Compression) or not" ${WITH_DISTRIBUTE})
@@ -147,6 +148,10 @@ option(WITH_ARM   "Compile PaddlePaddle with arm support"         OFF)
 option(WITH_SW   "Compile PaddlePaddle with sw support"         OFF)
 option(WITH_MUSL        "Compile with musl libc instead of gblic"  OFF)
 
+if (WITH_SYSTEM_GRPC)
+    add_definitions(-DPADDLE_WITH_SYSTEM_GRPC)
+endif()
+
 # PY_VERSION
 if(NOT PY_VERSION)
   set(PY_VERSION 2.7)
@@ -240,12 +245,6 @@ if(WITH_PROFILER)
     add_definitions(-DWITH_GPERFTOOLS)
 endif()
 
-if(WITH_DISTRIBUTE)
-    if(LINUX)
-        set(WITH_GLOO ON CACHE STRING "Enable GLOO when compiling WITH_DISTRIBUTE=ON." FORCE)
-    endif()
-endif()
-
 include(ccache)             # set ccache for compilation
 include(util)               # set unittest and link libs
 include(version)            # set PADDLE_VERSION
diff --git a/python/paddle/distributed/parallel.py b/python/paddle/distributed/parallel.py
index 4d60db6f06..ab8ab0c138 100644
--- a/python/paddle/distributed/parallel.py
+++ b/python/paddle/distributed/parallel.py
@@ -141,20 +141,6 @@ def init_parallel_env():
     _check_var_exists("PADDLE_TRAINERS_NUM")
     _check_var_exists("PADDLE_TRAINER_ENDPOINTS")
 
-    # 3: init gloo context (step 1: httpsever start)
-    ep_rank_0 = parallel_env.trainer_endpoints[0].split(":")
-    ep_rank = parallel_env.trainer_endpoints[parallel_env.rank].split(":")
-    manager = Manager()
-    # glboal dict to store status
-    http_server_d = manager.dict()
-    http_server_d["running"] = False
-    if parallel_env.rank == 0:
-        http_server = Process(
-            target=_start_kv_server, args=(int(ep_rank_0[1]), http_server_d))
-        http_server.daemon = True
-        http_server_d["running"] = True
-        http_server.start()
-
     # 4. init NCCL ParallelStrategy
     strategy = ParallelStrategy()
     if parallel_helper._is_parallel_ctx_initialized():
@@ -177,27 +163,6 @@ def init_parallel_env():
     parallel_helper._set_parallel_ctx(core.NCCLParallelContext(strategy, place))
     parallel_helper._init_parallel_ctx()
 
-    # 5: init gloo context (step 2: gloo init)
-    # dividing init_gloo into two part beacause nccl and gloo
-    # are separately looking for free ports which sometimes
-    # leads to port-conflict.
-    wait_server_ready([parallel_env.trainer_endpoints[0]])
-
-    gloo_strategy = core.GlooParallelStrategy()
-    gloo_strategy.rank = parallel_env.rank
-    gloo_strategy.rank_num = parallel_env.world_size
-    gloo_strategy.ip_address = ep_rank_0[0]
-    gloo_strategy.ip_port = int(ep_rank_0[1])
-    default_init_timeout_seconds = 3600
-    default_run_timeout_seconds = 9999999
-    gloo_strategy.init_seconds = default_init_timeout_seconds
-    gloo_strategy.run_seconds = default_run_timeout_seconds
-    gloo = core.GlooParallelContext(gloo_strategy)
-    gloo.init()
-    if parallel_env.rank == 0:
-        http_server_d["running"] = False
-        http_server.join()
-
 
 def get_rank():
     """